#!/usr/bin/env dart
// WebRTC çª—å£æ•è·éªŒè¯è„šæœ¬
// ç”¨æ³•: dart scripts/verify/verify_webrtc_window_capture.dart
//
// ç›®çš„ï¼šéªŒè¯ desktopCapturer.getSources(SourceType.Window) æ˜¯å¦å¯ç”¨ã€
// æ˜¯å¦èƒ½å®šä½åˆ° iTerm2 çª—å£ï¼Œå¹¶é€šè¿‡ getDisplayMedia æ‹¿åˆ° MediaStreamã€‚
//
// æ³¨æ„ï¼šè¿è¡Œæ—¶å¯èƒ½è§¦å‘ç³»ç»Ÿâ€œå±å¹•å½•åˆ¶/çª—å£å½•åˆ¶â€æƒé™å¼¹çª—ã€‚

import 'dart:io';
import 'package:flutter_webrtc/flutter_webrtc.dart';

Future<void> main() async {
  stdout.writeln('ğŸ” WebRTC çª—å£æ•è·éªŒè¯');
  stdout.writeln('=' * 50);

  if (!Platform.isMacOS && !Platform.isWindows && !Platform.isLinux) {
    stderr.writeln('âŒ å½“å‰å¹³å°ä¸æ”¯æŒ desktopCapturerï¼ˆéœ€è¦æ¡Œé¢å¹³å°ï¼‰');
    exit(1);
  }
  stdout.writeln('âœ… å¹³å°: ${Platform.operatingSystem}');

  stdout.writeln('\nğŸ“‹ Step 1/3: è°ƒç”¨ desktopCapturer.getSources (Window + Screen) ...');
  final sources = await desktopCapturer.getSources(
    types: [SourceType.Window, SourceType.Screen],
  );
  stdout.writeln('âœ… sources total: ${sources.length}');

  int windowCount = 0;
  int screenCount = 0;
  DesktopCapturerSource? iterm2;

  for (final s in sources) {
    if (s.type == SourceType.Window) {
      windowCount++;
      if (s.name.toLowerCase().contains('iterm')) {
        iterm2 ??= s;
      }
    } else if (s.type == SourceType.Screen) {
      screenCount++;
    }
  }

  stdout.writeln('ğŸ“Š windowCount=$windowCount screenCount=$screenCount');

  stdout.writeln('\nğŸ“‹ Step 2/3: æ‰“å°éƒ¨åˆ†çª—å£åˆ—è¡¨ï¼ˆæœ€å¤š 12 ä¸ªï¼‰...');
  int printed = 0;
  for (final s in sources.where((x) => x.type == SourceType.Window)) {
    stdout.writeln('  - window: name="${s.name}" id=${s.id}');
    printed++;
    if (printed >= 12) break;
  }

  if (sources.isEmpty) {
    stderr.writeln('âŒ æœªè·å–åˆ°ä»»ä½•å¯æ•è·æºï¼ˆsources ä¸ºç©ºï¼‰ã€‚è¯·æ£€æŸ¥æƒé™/ç¯å¢ƒã€‚');
    exit(1);
  }

  final DesktopCapturerSource target = iterm2 ??
      sources.firstWhere(
        (x) => x.type == SourceType.Window,
        orElse: () => sources.first,
      );

  stdout.writeln('\nğŸ“‹ Step 3/3: å°è¯• getDisplayMedia æ•è·ç›®æ ‡æº...');
  stdout.writeln('ğŸ¯ target: type=${target.type} name="${target.name}" id=${target.id}');

  final constraints = <String, dynamic>{
    'video': {
      'deviceId': {'exact': target.id},
      'mandatory': {
        'frameRate': 30,
        // NOTE: æœ‰äº›è®¾å¤‡ä¸Š hasCursor ä¼šå¯¼è‡´å´©æºƒï¼ˆä»“åº“å·²æœ‰æ³¨é‡Šï¼‰ï¼Œæ­¤å¤„ä¿æŒ falseã€‚
        'hasCursor': false,
      },
    },
    'audio': false,
  };

  try {
    stdout.writeln('  â³ calling navigator.mediaDevices.getDisplayMedia ...');
    final stream = await navigator.mediaDevices.getDisplayMedia(constraints);
    stdout.writeln('  âœ… got MediaStream id=${stream.id}');

    final videoTracks = stream.getVideoTracks();
    stdout.writeln('  âœ… videoTracks=${videoTracks.length}');
    if (videoTracks.isNotEmpty) {
      final track = videoTracks.first;
      stdout.writeln('     track.id=${track.id} kind=${track.kind} enabled=${track.enabled}');

      final settings = track.getSettings();
      stdout.writeln('     settings.width=${settings['width']} height=${settings['height']} fps=${settings['frameRate']}');
    }

    for (final t in stream.getTracks()) {
      t.stop();
    }
    stdout.writeln('  âœ… stopped stream tracks');
    stdout.writeln('\nâœ… WebRTC çª—å£æ•è·éªŒè¯é€šè¿‡');
  } catch (e) {
    stderr.writeln('  âŒ getDisplayMedia failed: $e');
    stderr.writeln('  ğŸ’¡ è‹¥æç¤ºæƒé™é—®é¢˜ï¼šmacOS ç³»ç»Ÿè®¾ç½® -> éšç§ä¸å®‰å…¨ -> å±å¹•å½•åˆ¶ï¼Œç»™å½“å‰ç»ˆç«¯/IDE æˆæƒã€‚');
    exit(2);
  }
}
